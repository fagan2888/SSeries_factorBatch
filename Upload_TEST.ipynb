{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Python 3.6\n",
    "# author: EJ Jang\n",
    "# date: 2018.06.14\n",
    "\n",
    "option = 'backfill'\n",
    "freq = 'M'\n",
    "# import sys\n",
    "# option = sys.argv[1]\n",
    "# freq = sys.argv[2]\n",
    "print('# Starting Upload Protocal for (\"{}\", \"{}\")\\n'.format(option, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "from batch_utils.common import must, chg_to_type\n",
    "from batch_utils.utils_dateSeq import batch_sequence\n",
    "from batch_utils.utils_db_alch2 import connectDB\n",
    "from batch_utils.utils_sql import create_table, update_table, check_exist\n",
    "import batch_utils.utils_upload as up\n",
    "\n",
    "# from scipy.stats import mode, kurtosis, skew\n",
    "# print(np.mean(valadj_))\n",
    "# print(np.median(valadj_))\n",
    "# print(kurtosis(valadj_))\n",
    "# print(skew(valadj_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Date Sequence to be made by this batch\n",
    "bkfil, rtvStart, seq_DT = batch_sequence(option, freq, rtvDays=60)\n",
    "print('>>> Factor Dates to be Uploaded:')\n",
    "if seq_DT.shape[0] > 8:\n",
    "    print('    ' + ', '.join(seq_DT.iloc[:3]) + ' ... ' + ', '.join(seq_DT.iloc[-3:]))\n",
    "else:\n",
    "    print('    ' + ', '.join(seq_DT))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "_read_folder = 'save_{}'.format('total' if bkfil else 'batch')\n",
    "print('>>> Checking Files to be uploaded from \"{}\" folder'.format(_read_folder))\n",
    "_tgt_types = ['comb', 'starmine', 'sedol', 'worldscope']\n",
    "\n",
    "upl_files = [f for f in os.listdir(_read_folder)\n",
    "             if f.split('_')[0] in _tgt_types]\n",
    "if 'IBES_ErnRev3M.p' in os.listdir(_read_folder):\n",
    "    upl_files.append('IBES_ErnRev3M.p')\n",
    "print('>>> Files to be Uploaded:')\n",
    "for k in range(0, len(upl_files), 5):\n",
    "    print('    ' + ' | '.join(upl_files[k: k + 3]))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "print('>>> Checking if \"FactorBuild_adjSignal.csv\" Exists:')\n",
    "factor_adjMap = pd.read_csv(\n",
    "    'batch_utils/key_files/FactorBuild_adjSignal.csv',\n",
    "    index_col=0)\n",
    "print(factor_adjMap.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "print('>>> Getting QAD Master Security Information for Reference Info:')\n",
    "conn = connectDB('MSSQL_QAD')\n",
    "secInf = up.get_refInformation(conn)\n",
    "conn.close()\n",
    "print('    Done.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "server_ = 'MSSQL_DEV'\n",
    "db_name = 'EJ_WRK_FACTORS3'\n",
    "print('>>> Checking if DB: {} exists:'.format(db_name))\n",
    "conn = connectDB('MSSQL_DEV')\n",
    "if not check_exist(conn, db_name):\n",
    "    while True:\n",
    "        input_ = input('    Table does not exist! Proceed to create one?? (y/n)')\n",
    "        if input_ in ['y', 'n']:\n",
    "            break\n",
    "        else:\n",
    "            print('    Input should be y/n. Try Again.')\n",
    "    if input_ == 'y':\n",
    "        create_table(conn, db_name, up.typeStr, primary=up.primary)\n",
    "    else:\n",
    "        conn.close()\n",
    "        exit()\n",
    "else:\n",
    "    print('    Exists. Checked.\\n')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# UPLOADING SCRIPT\n",
    "def unloadedFactors_log(filename, StyleName, morethan_):\n",
    "    today_ = dt.date.today().strftime('%Y%m%d')\n",
    "    print('    !!! No data to update \"{}\"'.format(fctr))\n",
    "    print('    !!! Current DB maxDate is \"{}\"'.format(morethan_))\n",
    "    print('    !!! Leaving Log in \"WARN_unloadedFactors_{}.log\"'.format(morethan_))\n",
    "    with open('WARN_unloadedFactors_{}.log'.format(morethan_), 'a+', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        writer.writerow([filename, StyleName, morethan_])\n",
    "\n",
    "for file in upl_files:\n",
    "    print(\">>> Opening file: '{}'\".format(file))\n",
    "    df = pd.read_pickle('{}/{}'.format(_read_folder, file))\n",
    "    fctr_lst = df['StyleName'].unique().tolist()\n",
    "    for k in range(0, len(fctr_lst), 5):\n",
    "        print('    # Factors List:')\n",
    "        print('    # ' + ' | '.join(fctr_lst[k:k + 5]))\n",
    "\n",
    "    fctr_lstMap = factor_adjMap.reindex(fctr_lst)\n",
    "    assert fctr_lstMap['Transform'].notnull().all(), (\n",
    "        \"Factor missing in 'FactorBuild_adjSignal.csv'!\")\n",
    "\n",
    "    upload_order = fctr_lstMap['Transform'].unique().tolist()\n",
    "    for adj_ in upload_order:\n",
    "        # adj_ = 'r'\n",
    "        list_ = fctr_lstMap.query(\"Transform=='{}'\".format(adj_)).index.tolist()\n",
    "\n",
    "        # COPY the upload sample into 'workDF'\n",
    "        for j, fctr in enumerate(list_):\n",
    "            print('    ({}) Processing {}:'.format(j, fctr))\n",
    "            conn = connectDB(server_)\n",
    "\n",
    "            workDF = df[df['StyleName']==fctr].copy()\n",
    "            morethan_ = up.check_maxDate(conn, db_name=db_name, styleName=fctr)\n",
    "            workDF = workDF[workDF['BASE_DT'] > morethan_]\n",
    "            if workDF.shape[0] == 0:\n",
    "                unloadedFactors_log(file, fctr, morethan_)\n",
    "                conn.close()\n",
    "                continue\n",
    "            else:\n",
    "                # setup before adjusting\n",
    "                workDF.rename(columns={'RGN_TP_CD': 'CD_ref'}, inplace=True)\n",
    "                if 'ref' not in workDF.columns.tolist():\n",
    "                    workDF['ref'] = None\n",
    "\n",
    "                # adjusting\n",
    "                workDF, _ = up.adjScore_DFValue_(workDF, adj_, copy=True)\n",
    "                workDF['Value_adj'] = workDF.groupby(\n",
    "                    'BASE_DT')['Value_adj'].apply(up.winsor_medZ4)\n",
    "\n",
    "                col_order = ['BASE_DT', 'StyleName', 'TMSRS_CD', 'Code', 'CD_ref',\n",
    "                            'Value_', 'Value_adj', 'adj_op', 'freq', 'ref']\n",
    "                workDF = workDF[col_order]\n",
    "\n",
    "                if workDF['Value_adj'].isin([np.Inf, -np.Inf]).any():\n",
    "                    raise AssertionError(\n",
    "                        'Infinity Values (Value_adj) exist in {}_{}'.format(adj_, fctr))\n",
    "\n",
    "                if workDF['Value_'].isin([np.Inf, -np.Inf]).any():\n",
    "                    raise AssertionError(\n",
    "                        'Infinity Values (Value_) exist in {}_{}'.format(adj_, fctr))\n",
    "\n",
    "                workDF = pd.merge(workDF, secInf, on='TMSRS_CD', how='left')\n",
    "                NOW_DT = dt.datetime.now()\n",
    "                tmStr = NOW_DT.strftime(\"%Y-%m-%d %H:%M:%S.\") + format(\n",
    "                    int(round(NOW_DT.microsecond / 1000, 0)), \"03d\")\n",
    "                workDF['REG_DTTM'] = tmStr\n",
    "                workDF['REG_EMP_NMB'] = '2150416'\n",
    "                workDF['LST_DTTM'] = tmStr\n",
    "                workDF['LST_EMP_NMB'] = '2150416'\n",
    "                workDF = workDF[up.typeStr.index]\n",
    "                \n",
    "                #*--- cleanse values to fit in sql table ---\n",
    "                workDF['freq'] = workDF['freq'].str.replace('Norm', 'Nr')\n",
    "                str_cols = ['Code', 'CD_ref', 'ref_CTRY', 'adj_op',\n",
    "                            'ref_Name', 'ref_SEDOL', 'ref', 'freq']\n",
    "                for col in str_cols:\n",
    "                    workDF[col] = workDF[col].apply(\n",
    "                        lambda x: x if isinstance(x, str) else 'NULL')\n",
    "                float_cols = ['Value_', 'Value_adj']\n",
    "                for col in float_cols:\n",
    "                    workDF[col] = workDF[col].round(8)\n",
    "                workDF['ref_Name'] = workDF['ref_Name'].apply(\n",
    "                    lambda x: re.sub(\"'\", \" \", x))\n",
    "                #*--- cleanse values to fit in sql table ---\n",
    "\n",
    "                print('\\n    - Uploading ({}) {}'.format(adj_, fctr))\n",
    "                update_table(conn, db_name, workDF, up.typeStr, verbose=True)\n",
    "                conn.close()\n",
    "                continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
